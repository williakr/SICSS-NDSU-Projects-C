---
title: "Cleaning the corpus"
output: html_notebook
---

# Setup

```{r}
library(tidyverse)
library(quanteda)
library(quanteda.corpora)
library(quanteda.textplots)
library(quanteda.textstats)
library(quanteda.sentiment)
library(tm)
library(tidytext)
```

# Reading in the data

```{r}
comments_data <- read_csv("../data/pdfcomments_scraped.csv") # replace with the file with attachments
comments_corpus <- corpus(comments_data$commentText, docnames = comments_data$commentID)
```

# Basic checks

```{r}
comments_tokens <- tokens(
  x = comments_corpus,
  what = "word",
  remove_punct = TRUE
)

dfm(comments_tokens,
    tolower = TRUE) %>% colSums() %>% sort(decreasing = TRUE) %>%
  as.data.frame()
```

Inspecting some of the problematic tokens in context
```{r}
kwic(comments_tokens, pattern = "br")
kwic(comments_tokens, pattern = "#39")
kwic(comments_tokens, pattern = "quot")
kwic(comments_tokens, pattern = "rsquo")
kwic(comments_tokens, pattern = "ldquo")
kwic(comments_tokens, pattern = "rdquo")
kwic(comments_tokens, pattern = "1")
kwic(comments_tokens, pattern = "11") # September 11, 2001
kwic(comments_tokens, pattern = "2")
kwic(comments_tokens, pattern = "o") # confused
kwic(comments_tokens, pattern = "b") # list item; also remove "c"
kwic(comments_tokens, pattern = "+")
```
Summary of problematic tokens:

* HTML tags: "<br>"
* Special characters: "#39", "quot", "rsquo", "ldquo", "rdquo", "�", "o"
* Contractions: "re", "m", "ve"
* List items: some numbers (esp. 1, 2, 3,...) and "b" and "c" and probably "a" too
* Numbers: some numbers are meaningful, like 9/11 is an important historical event being referenced. Others are not meaningful
* Other: "+"

```{r}
comments_corpus[str_detect(comments_corpus, pattern = "�")][[1]]
```

